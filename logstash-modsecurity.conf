##########################################################
##########################################################
#
# Example Modsecurity audit log ingestor
# configuration for Logstash
#
# @author bitsofinfo.g[at]gmail.com
# built/tested w logstash v1.3.x line
#
#
# @see http://logstash.net/
# @see https://github.com/SpiderLabs/ModSecurity/wiki/ModSecurity-2-Data-Formats
# @see http://bitsofinfo.wordpress.com/2013/09/19/logstash-for-modsecurity-audit-logs/
#
# @license http://www.apache.org/licenses/LICENSE-2.0
#
# @notes NOTE: this is not perfect and I am no Ruby expert
#        however this worked when processing quite a bit of
#        high volume mod-sec logs with lots of different
#        variations in what A-K sections were and were not
#        present. At a minimum its a good starting point
#        to start tackling a complex log format.
#
# Be careful w/ the custom ruby filter blocks and be aware
# of https://logstash.jira.com/browse/LOGSTASH-1375
#
# This config file for whatever reason will not run
# if you try to add the "-- web" option onto the logstash
# flat jar. This has been reported to the developers.
# Recommend you run this without the "-- web" option and just
# hook up Kibana separately.
#
# Enable the "-v" verbose option when starting logstash
# to aid in debugging things. Disable the "-v" option
# when running in real/non-debug environment
#
#
##########################################################
##########################################################

input {
  file {
    # IMPORTANT! set this correctly to the charset
    # that your server writes these log files in
    charset => "US-ASCII"
    path => "/path/to/your/modsec/audit/logs/*.log"
    type => "mod_security"

    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    # merge all modsec events for a given entity into the same event.
    # so essentially the modsec -Z marker is used as the splitter
    # which is the end of each modsec logical event in the logfile
    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    codec => multiline {
      pattern => "^--[a-fA-F0-9]{8}-Z--$"
      negate => true
      what => previous
    }
  }
}

filter {

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Due to the complexity of the collapsed single string
  # we get from multiline and the variance of exactly
  # which modsec sections (A-K) may or may not be in each
  # log entry, we run some custom ruby code that will
  # split on each modsec "section" and store each found in
  # new fields named "rawSection[A-K]" as appropriate, the value
  # of each of these fields contains the raw un-parsed data
  # from that modsec section. Sections that are non-existant
  # will not have a key in "fields"
  #
  # A bit long and crazy yes, but after spending many hours
  # just doing this w/ grok patterns, this ended up being the
  # most reliable way to break up this in-consistent format into
  # more usable blocks
  #
  # @see https://github.com/SpiderLabs/ModSecurity/wiki/ModSecurity-2-Data-Formats
  #
  # READ the above to get a good understanding of the sections
  # and which ones can actively contain data depending on your modsec
  # version and environment!
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  ruby {
    code => "
        if !event['message'].nil?
            modSecSectionData = event['message'].split(/(?:--[a-fA-F0-9]{8}-([A-Z])--)/)
            modSecSectionData.shift
            for i in 0..((modSecSectionData.length-1)/2)
                sectionName = 'rawSection'.concat(modSecSectionData.shift)
                sectionData = modSecSectionData.shift
                sectionName = sectionName.strip
                if !sectionData.nil?
                    sectionData = sectionData.strip
                end
                event.to_hash.merge!(sectionName => sectionData)
            end
        end
      "
  }



  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section A (general event basics)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  grok {
    match => {
      "rawSectionA" => "\[%{L1_TIMESTAMP:modsec_timestamp}\] %{DATA:uniqueId} %{IP:sourceIp} %{INT:sourcePort} %{IP:destIp} %{INT:destPort}"
    }
    patterns_dir => "./patterns/logstash_modsecurity_patterns"
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section B (request related line 1)
  # note line one could be garbage OR adhere to the
  # httpMethod [space] uri [space] protocol pattern
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  # if a legit line... normal http request
  if [rawSectionB] =~ /.*?\s\S+\s.+\n{1}/ {

    grok {
      match => {
        "rawSectionB" => "%{DATA:httpMethod}\s(?<requestedUri>\S+)\s(?<incomingProtocol>.+?)\n{1}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

  # not a legit line.. invalid http request, grab first line and dump in the httpMethod
  } else {

    grok {
      match => {
        "rawSectionB" => "(?<httpMethod>^(.*)$)"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section C (post data)
  # this is not always present
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionC] =~ /.+/ {
    grok {
      match => {
        "rawSectionC" => "(?<requestBody>.+)"
       }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section B (request headers, line 2+)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionB] =~ /.+?\n(?m).+/ {

    grok {
      match => {
        "rawSectionB" => ".+?\n(?m)(?<raw_requestHeaders>.+)"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

  }
  
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Optionally deal w/ Section E (intended response data)
  # this is not always present
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionE] =~ /.+/ {
    # you can deal w/ this if you want to here...
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out server protocol/HTTP status from Section F (response related, line 1)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   # response section (NO headers)
  if [rawSectionF] =~ /(.+?)\s(.+?)$/ {
        		
      grok {
        singles => true
        match => {
          "rawSectionF" => "(?<serverProtocol>.+?)\s(?<responseStatus>.+?)$"
        }
        patterns_dir => "./patterns/logstash_modsecurity_patterns"
      }

  # response section (WITH headers)
  } else if [rawSectionF] =~ /(.+?)\s(.+?)\n{1}/ {
  
    grok {
      singles => true
      match => {
        "rawSectionF" => "(?<serverProtocol>.+?)\s(?<responseStatus>.+?)\n{1}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

  } 


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out response headers from Section F (response headers, lines 2+)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # only if the server responded...WITH headers...
    if [rawSectionF] =~ /(.+?)\s(.+)\n{1}/ {

      grok {
        match => {
          "rawSectionF" => ".+?\n(?m)(?<raw_responseHeaders>.+)"
        }
        patterns_dir => "./patterns/logstash_modsecurity_patterns"
      }
    }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Promote real request IP to a field if it exists
  # in the request headers section
  #
  # NOTE this is an example of promoting a custom header to a first
  # class field that might be set by a app firewall or other
  # upstream proxy
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /X-Forwarded-For:/ {

    grok {
      match => {
        "raw_requestHeaders" => "X-Forwarded-For: %{IPORHOST:XForwardedFor}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Example of looking for a specific Cookie and promoting
  # it to a first class field
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /Cookie/ and [raw_requestHeaders] =~ /myCookie=.+\b/ {

    grok {
      match => {
        "raw_requestHeaders" => "(?<myCookie>myCookie[^; \s]+)"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert raw request headers into a key/value
  # pair map
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /.+/ {
    kv {
      source => "raw_requestHeaders"
      field_split => "\n"
      value_split => ":"
      target => "requestHeaders"
    }


    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "
          requestHeaders = event.to_hash['requestHeaders']
          requestHeaders.each { |k, v|
            if !v.nil? and v.is_a? String
              requestHeaders[k] = v.strip
            end
          }
        "
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert raw response headers into a key/value
  # pair map
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_responseHeaders] =~ /.+/ {
    kv {
      source => "raw_responseHeaders"
      field_split => "\n"
      value_split => ":"
      target => "responseHeaders"
    }

    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "
          responseHeaders = event.to_hash['responseHeaders']
          responseHeaders.each { |k, v|
            if !v.nil? and v.is_a? String
              responseHeaders[k] = v.strip
            end
          }
        "
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Explode all "Messages" from sectionH to first
  # class objects w/ properties and store in an array
      # called "auditLogTrailerMessages"
  #
  # Secondly - proceed to extract all distinct "severities"
  # and store them in a top-level "modsecSeverities" array
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /Message:/ {

    # build the auditlog trailer messages
    ruby {
      code => "
          def extractVal(pattern, fromString, storeResultIn, underKeyName, multiValues=false)
            if multiValues
              result = fromString.scan(pattern)
              if !result.empty?
                storeResultIn[underKeyName] = result.flatten
              end
            else
              result = pattern.match(fromString)
              if !result.nil?
                storeResultIn[underKeyName] = result[1]
              end
            end
          end

          auditLogTrailerMessages = Array.new()
          trailer_array = event.to_hash['rawSectionH'].split(/\n/)
          trailer_array.each do |entry|
            if entry.match(/^Message: /)
              msg = Hash.new()
              extractVal(/Message: (.+)\s($|(\s*\[file))/, entry, msg, 'info')
              extractVal(/\[file \"(.*?)\"\]/, entry, msg, 'file')
              extractVal(/\[line \"(.*?)\"\]/, entry, msg, 'line')
              extractVal(/\[id \"(.*?)\"\]/, entry, msg, 'id')
              extractVal(/\[msg \"(.*?)\"\]/, entry, msg, 'msg')
              extractVal(/\[severity \"(.*?)\"\]/, entry, msg, 'severity')
              extractVal(/\[data \"(.*?)\"\]/, entry, msg, 'data')
              extractVal(/\[tag \"(.*?)\"\]/, entry, msg, 'tag')
              auditLogTrailerMessages.push(msg)
            end
          end

          event.to_hash.merge!('auditLogTrailerMessages' => auditLogTrailerMessages)
        "
    }

    # extract distinct severities from the messages built above
    ruby {
      code => "
          modsecSeverities = Set.new
          trailerMsgs = event.to_hash['auditLogTrailerMessages']
          trailerMsgs.each {|m|
            if m.key?('severity')
              modsecSeverities.add(m['severity'])
            end
          }
          event.to_hash.merge!('modsecSeverities' => modsecSeverities.to_a)
        "
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert section H into a key/value
  # pair map called "auditLogTrailer"
  # delete the 'Message' sub-key and replace with 'auditLogTrailerMessages'
  # built in the previous section under key 'messages', then
  # delete auditLogTrailerMessages
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /.+/ {
    kv {
      source => "rawSectionH"
      field_split => "\n"
      value_split => ":"
      target => "auditLogTrailer"
    }

    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "
          auditLogTrailer = event.to_hash['auditLogTrailer']
          auditLogTrailerMessages = event.to_hash['auditLogTrailerMessages']
          auditLogTrailer.each { |k, v|
            if !v.nil? and v.is_a? String
              auditLogTrailer[k] = v.strip
            end
          }
          auditLogTrailer.delete('Message')
          auditLogTrailer['messages'] = auditLogTrailerMessages
          event.to_hash.delete('auditLogTrailerMessages')
        "
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Promote raw "stopwatch" in section H
  # to a real date. The value is in microseconds
  # since epoch (convert to seconds) then
  # run through logstashes' routine. The result
  # of this is that the logstash @timestamp is converted
  # to be the modsec stopwatch timestamp value. We
  # also retain the milliseconds and seconds fields
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /Stopwatch/ {

    grok {
      match => {
        "rawSectionH" => "Stopwatch: %{WORD:event_date_microseconds}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

    mutate {
      convert => [ "event_date_microseconds", "float" ]
    }

    # micro -> milli
    ruby {
      code => "
          event_date_milliseconds = (event.to_hash['event_date_microseconds'] / 1000.0)
          event.to_hash.merge!('event_date_milliseconds' => event_date_milliseconds)
        "
    }

    # milli -> seconds
    ruby {
      code => "
          event_date_seconds = (event.to_hash['event_date_milliseconds'] / 1000.0)
          event.to_hash.merge!('event_date_seconds' => event_date_seconds)
        "
    }

    # NOTE!, this forces the event's @timestamp to be = to the stopwatch value
    date {
      match => [ "event_date_seconds", "UNIX" ]
      timezone => "GMT"
    }

    # a second copy of a iso8601 date
    ruby {
      code => "
          event.to_hash.merge!('event_timestamp' => (Time.at(event.to_hash['event_date_seconds']).gmtime).iso8601(3))
        "
    }

  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Create a new field for the real requestor
  # ip address containing the GEOIP info
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  geoip {
    source => "XForwardedFor"
    target => "XForwardedFor-GEOIP"
  }
  
  # Optional, if not fixed: massage values to UTF-8... hack  @see https://logstash.jira.com/browse/LOGSTASH-1372
  # convert Strings to UTF-8, leave as-is otherwise
  #ruby {
  #  code => "
  #      geoip = event.to_hash['XForwardedFor-GEOIP']
  #      if !geoip.nil?
  #        newgeoip = Hash.new()
  #        geoip.each do |key,value|
  #          if !value.nil? and value.is_a? String
  #            newgeoip[key] = value.encode('UTF-8')
  #          else
  #            newgeoip[key] = value
  #          end
  #        end
  #        event.to_hash.merge!('XForwardedFor-GEOIP' => newgeoip)
  #      end
  #    "
  #}


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert section K into an array
  # and rename it to "matchedRules"
  # also create an array of just the
  # secRuleIds that were located in
  # sectionK
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionK] =~ /.+/ {

    # hack.. @see https://logstash.jira.com/browse/LOGSTASH-1331
    mutate {
      gsub => [ "rawSectionK", "\n", "~" ]
      split => [ "rawSectionK" , "~" ]
    }

    mutate {
      rename => [ "rawSectionK", "matchedRules"]
    }

    ruby {
      code => "
          secRuleIds = Array.new()
          matchedRules_array = event.to_hash['matchedRules']
          matchedRules_array.each do |entry|
            if entry.match(/^SecRule /) and entry.match(/,id:/)
              secRuleIds.push(/,id:(?<ruleId>\d+)/.match(entry)[:ruleId])
            end
          end
          event.to_hash.merge!('secRuleIds' => secRuleIds)
        "
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Get rid of fields that we don't need anymore
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  mutate {
    remove_field => [ "message", "raw_responseHeaders", "raw_requestHeaders"]
  }

}

output {

  # turn this off when ready to run in a 
  # real prod environment and get rid of the 
  # "-v" flag when starting logstash
  stdout { }
  
}
