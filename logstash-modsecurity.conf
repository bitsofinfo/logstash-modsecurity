##########################################################
##########################################################
#
# Example Modsecurity audit log ingestor
# configuration for Logstash
#
# @author bitsofinfo.g[at]gmail.com
# built/tested w logstash v1.3.x line
#
#
# @see http://logstash.net/
# @see https://github.com/SpiderLabs/ModSecurity/wiki/ModSecurity-2-Data-Formats
# @see http://bitsofinfo.wordpress.com/2013/09/19/logstash-for-modsecurity-audit-logs/
#
# @license http://www.apache.org/licenses/LICENSE-2.0
#
# @notes NOTE: this is not perfect and I am no Ruby expert
#        however this worked when processing quite a bit of
#        high volume mod-sec logs with lots of different
#        variations in what A-K sections were and were not
#        present. At a minimum its a good starting point
#        to start tackling a complex log format.
#
# Be careful w/ the custom ruby filter blocks and be aware
# of https://logstash.jira.com/browse/LOGSTASH-1375
#
# This config file for whatever reason will not run
# if you try to add the "-- web" option onto the logstash
# flat jar. This has been reported to the developers.
# Recommend you run this without the "-- web" option and just
# hook up Kibana separately.
#
# Enable the "-v" verbose option when starting logstash
# to aid in debugging things. Disable the "-v" option
# when running in real/non-debug environment
#
#
##########################################################
##########################################################

input {
  file {
    # IMPORTANT! set this correctly to the charset
    # that your server writes these log files in
    charset => "US-ASCII"
    path => "/path/to/your/modsec/audit/logs/*.log"
    type => "mod_security"
  }
}

filter {

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # merge all modsec events for a given entity into the same event.
  # so essentially the modsec -A marker is used as the splitter
  # which is the start of each modsec logical event in the logfile
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  multiline {
    pattern => "^--[a-fA-F0-9]{8}-A--$"
    negate => true
    what => previous
    type => "mod_security"
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Due to the complexity of the collapsed single string
  # we get from multiline and the variance of exactly
  # which modsec sections (A-K) may or may not be in each
  # log entry, we run some custom ruby code that will
  # split on each modsec "section" and store each found in
  # new fields named "rawSection[A-K]" as appropriate, the value
  # of each of these fields contains the raw un-parsed data
  # from that modsec section. Sections that are non-existant
  # will not have a key in "fields"
  #
  # A bit long and crazy yes, but after spending many hours
  # just doing this w/ grok patterns, this ended up being the
  # most reliable way to break up this in-consistent format into
  # more usable blocks
  #
  # @see https://github.com/SpiderLabs/ModSecurity/wiki/ModSecurity-2-Data-Formats
  #
  # READ the above to get a good understanding of the sections
  # and which ones can actively contain data depending on your modsec
  # version and environment!
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  ruby {
    code => "if !event['message'].nil?; modSecSectionData = event['message'].split(/(--[a-fA-F0-9]{8}-[A-Z]--)/); modSecSectionData.shift;  for i in 0..(modSecSectionData.length-1); sectionName = modSecSectionData.shift; if sectionName.nil?; break; end; sectionData = modSecSectionData.shift; if sectionName.include? '-A--'; sectionName = 'rawSectionA'; elsif sectionName.include? '-B--'; sectionName = 'rawSectionB'; elsif sectionName.include? '-C--'; sectionName = 'rawSectionC'; elsif sectionName.include? '-D--'; sectionName = 'rawSectionD'; elsif sectionName.include? '-E--'; sectionName = 'rawSectionE'; elsif sectionName.include? '-F--'; sectionName = 'rawSectionF'; elsif sectionName.include? '-G--'; sectionName = 'rawSectionG'; elsif sectionName.include? '-H--'; sectionName = 'rawSectionH'; elsif sectionName.include? '-I--'; sectionName = 'rawSectionI'; elsif sectionName.include? '-J--'; sectionName = 'rawSectionJ'; elsif sectionName.include? '-K--'; sectionName = 'rawSectionK'; else; sectionName = ''; end;if !sectionName.nil? and sectionName != '' and sectionName != 'null' and sectionName != ' '; sectionName = sectionName.strip; if !sectionData.nil?; sectionData = sectionData.strip; end; if !sectionName.nil? and sectionName != '' and sectionName != 'null' and sectionName != ' '; event.to_hash.merge!(sectionName => sectionData); end; end; end; end"
  }



  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section A (general event basics)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  grok {
    match => {
      "rawSectionA" => "\[%{L1_TIMESTAMP:modsec_timestamp}\] %{DATA:uniqueId} %{IP:sourceIp} %{INT:sourcePort} %{IP:destIp} %{INT:destPort}"
    }
    patterns_dir => "./patterns/logstash_modsecurity_patterns"
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section B (request related line 1)
  # note line one could be garbage OR adhere to the
  # httpMethod [space] uri [space] protocol pattern
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  # if a legit line... normal http request
  if [rawSectionB] =~ /.*?\s\S+\s.+\n{1}/ {

    grok {
      match => {
        "rawSectionB" => "%{DATA:httpMethod}\s(?<requestedUri>\S+)\s(?<incomingProtocol>.+)\n{1}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

  # not a legit line.. invalid http request, grab first line and dump in the httpMethod
  } else {

    grok {
      match => {
        "rawSectionB" => "(?<httpMethod>^(.*)$)"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section C (post data)
  # this is not always present
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionC] =~ /.+/ {
    grok {
      match => {
        "rawSectionC" => "(?<requestBody>.+)"
       }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out fields from Section B (request headers, line 2+)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionB] =~ /.+\n(?m).+/ {

    grok {
       match => {
         "rawSectionB" => ".+\n(?m)(?<raw_requestHeaders>.+)"
       }
       patterns_dir => "./patterns/logstash_modsecurity_patterns"
     }

  }
  
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Optionally deal w/ Section E (intended response data)
  # this is not always present
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionE] =~ /.+/ {
    # you can deal w/ this if you want to here...
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out server protocol/HTTP status from Section F (response related, line 1)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   # response section (NO headers)
  if [rawSectionF] =~ /(.+?)\s(.+?)$/ {
        
        		
      grok {
              singles => true
              match => {
                      "rawSectionF" => "(?<serverProtocol>.+?)\s(?<responseStatus>.+)$"
                      }
              patterns_dir => "./patterns/logstash_modsecurity_patterns"
      }

  # response section (WITH headers)
  } else if [rawSectionF] =~ /(.+?)\s(.+)\n{1}/ {
  
    grok {
            singles => true
            match => {
                    "rawSectionF" => "(?<serverProtocol>.+?)\s(?<responseStatus>.+)\n{1}"
                    }
            patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

  } 


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Parse out response headers from Section F (response headers, lines 2+)
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    # only if the server responded...WITH headers...
    if [rawSectionF] =~ /(.+?)\s(.+)\n{1}/ {

      grok {
        match => {
          "rawSectionF" => ".+\n(?m)(?<raw_responseHeaders>.+)"
        }
        patterns_dir => "./patterns/logstash_modsecurity_patterns"
      }
    }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Promote real request IP to a field if it exists
  # in the request headers section
  #
  # NOTE this is an example of promoting a custom header to a first
  # class field that might be set by a app firewall or other
  # upstream proxy
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /X-Forwarded-For:/ {

    grok {
      match => {
        "raw_requestHeaders" => "X-Forwarded-For: %{IPORHOST:XForwardedFor}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Example of looking for a specific Cookie and promoting
  # it to a first class field
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /Cookie/ and [raw_requestHeaders] =~ /myCookie=.+\b/ {

    grok {
      match => {
        "raw_requestHeaders" => "(?<myCookie>myCookie[^; \s]+)"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert raw request headers into a key/value
  # pair map
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_requestHeaders] =~ /.+/ {
    kv {
      source => "raw_requestHeaders"
      field_split => "\n"
      value_split => ":"
      target => "requestHeaders"
    }


    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "requestHeaders = event.to_hash['requestHeaders']; requestHeaders.each { |k, v| if !v.nil? and v.is_a? String; requestHeaders[k] = v.strip; end; };"
    }
  }

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert raw response headers into a key/value
  # pair map
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [raw_responseHeaders] =~ /.+/ {
    kv {
      source => "raw_responseHeaders"
      field_split => "\n"
      value_split => ":"
      target => "responseHeaders"
    }

    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "responseHeaders = event.to_hash['responseHeaders']; responseHeaders.each { |k, v| if !v.nil? and v.is_a? String; responseHeaders[k] = v.strip; end; };"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Explode all "Messages" from sectionH to first
  # class objects w/ properties and store in an array
      # called "auditLogTrailerMessages"
  #
  # Secondly - proceed to extract all distinct "severities"
  # and store them in a top-level "modsecSeverities" array
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /Message:/ {

    # build the auditlog trailer messages
    ruby {
      code => "def extractVal(pattern, fromString, storeResultIn, underKeyName); result = pattern.match(fromString); if !result.nil?; storeResultIn[underKeyName] = result[1]; end; end; auditLogTrailerMessages = Array.new(); trailer_array = event.to_hash['rawSectionH'].split(/\n/); trailer_array.each do |entry|; if entry.match(/^Message: /); msg = Hash.new(); extractVal(/Message: (.+)\s($|(\s*\[file))/, entry, msg, 'info'); extractVal(/\[file \"(.*?)\"\]/, entry, msg, 'file'); extractVal(/\[line \"(.*?)\"\]/, entry, msg, 'line'); extractVal(/\[id \"(.*?)\"\]/, entry, msg, 'id'); extractVal(/\[msg \"(.*?)\"\]/, entry, msg, 'msg'); extractVal(/\[severity \"(.*?)\"\]/, entry, msg, 'severity'); extractVal(/\[data \"(.*?)\"\]/, entry, msg, 'data');extractVal(/\[tag \"(.*?)\"\]/, entry, msg, 'tag'); auditLogTrailerMessages.push(msg); end; end; event.to_hash.merge!('auditLogTrailerMessages' => auditLogTrailerMessages);"
    }

    # extract distinct severities from the messages built above
    ruby {
      code => "modsecSeverities = Set.new; trailerMsgs = event.to_hash['auditLogTrailerMessages']; trailerMsgs.each {|m| modsecSeverities.add(m['severity']);}; event.to_hash.merge!('modsecSeverities' => modsecSeverities.to_a);"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert section H into a key/value
  # pair map called "auditLogTrailer"
  # delete the 'Message' sub-key and replace with 'auditLogTrailerMessages'
  # built in the previous section under key 'messages', then
  # delete auditLogTrailerMessages
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /.+/ {
    kv {
      source => "rawSectionH"
      field_split => "\n"
      value_split => ":"
      target => "auditLogTrailer"
    }

    # trim leading/trailing hack  @see https://logstash.jira.com/browse/LOGSTASH-1369
    ruby {
      code => "auditLogTrailer = event.to_hash['auditLogTrailer']; auditLogTrailerMessages = event.to_hash['auditLogTrailerMessages']; auditLogTrailer.each { |k, v| if !v.nil? and v.is_a? String; auditLogTrailer[k] = v.strip; end; }; auditLogTrailer.delete('Message'); auditLogTrailer['messages'] = auditLogTrailerMessages; event.to_hash.delete('auditLogTrailerMessages');"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Promote raw "stopwatch" in section H
  # to a real date. The value is in microseconds
  # since epoch (convert to seconds) then
  # run through logstashes' routine. The result
  # of this is that the logstash @timestamp is converted
  # to be the modsec stopwatch timestamp value. We
  # also retain the milliseconds and seconds fields
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionH] =~ /Stopwatch/ {

    grok {
      match => {
        "rawSectionH" => "Stopwatch: %{WORD:event_date_microseconds}"
      }
      patterns_dir => "./patterns/logstash_modsecurity_patterns"
    }

    mutate {
      convert => [ "event_date_microseconds", "float" ]
    }

    # micro -> milli
    ruby {
      code => "event_date_milliseconds = (event.to_hash['event_date_microseconds'] / 1000.0); event.to_hash.merge!('event_date_milliseconds' => event_date_milliseconds);"
    }

    # milli -> seconds
    ruby {
      code => "event_date_seconds = (event.to_hash['event_date_milliseconds'] / 1000.0); event.to_hash.merge!('event_date_seconds' => event_date_seconds);"
    }

    # NOTE!, this forces the event's @timestamp to be = to the stopwatch value
    date {
      match => [ "event_date_seconds", "UNIX" ]
      timezone => "GMT"
    }

    # a second copy of a iso8601 date
    ruby {
      code => "event.to_hash.merge!('event_timestamp' => (Time.at(event.to_hash['event_date_seconds']).gmtime).iso8601(3));"
    }

  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Create a new field for the real requestor
  # ip address containing the GEOIP info
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  geoip {
    source => "XForwardedFor"
    target => "XForwardedFor-GEOIP"
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Convert section K into an array
  # and rename it to "matchedRules"
  # also create an array of just the
  # secRuleIds that were located in
  # sectionK
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  if [rawSectionK] =~ /.+/ {

    # hack.. @see https://logstash.jira.com/browse/LOGSTASH-1331
    mutate {
      gsub => [ "rawSectionK", "\n", "~" ]
      split => [ "rawSectionK" , "~" ]
    }

    mutate {
      rename => [ "rawSectionK", "matchedRules"]
    }

    ruby {
      code => "secRuleIds = Array.new(); matchedRules_array = event.to_hash['matchedRules'];  matchedRules_array.each do |entry|;  if entry.match(/^SecRule /) and entry.match(/,id:/);  secRuleIds.push(/,id:(?<ruleId>\d+)/.match(entry)[:ruleId]); end; end; event.to_hash.merge!('secRuleIds' => secRuleIds);"
    }
  }


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # Get rid of fields that we don't need anymore
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  mutate {
    remove_field => [ "message", "raw_responseHeaders", "raw_requestHeaders"]
  }

}

output {

  # turn this off when ready to run in a 
  # real prod environment and get rid of the 
  # "-v" flag when starting logstash
  stdout { }
  
}
